{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9b1093ef22d456896ebb259c87047ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6477f5b91f5472b88abc77d3c583a75",
              "IPY_MODEL_2cc388de1e6d471cb36fc79978ea03c6",
              "IPY_MODEL_848ef537c6bc40cebda2bbd36f6d9982"
            ],
            "layout": "IPY_MODEL_35075f7cf373419493f10aec0f4619d2"
          }
        },
        "b6477f5b91f5472b88abc77d3c583a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca441b8da144e879308985081b900c8",
            "placeholder": "​",
            "style": "IPY_MODEL_a9ca3d4226ee4b5185cd0b28c8481f17",
            "value": "Downloading builder script: "
          }
        },
        "2cc388de1e6d471cb36fc79978ea03c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5258a69b94a8430f949231abc0cc293a",
            "max": 2848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a68b69ca319427badbf1df3e34f941c",
            "value": 2848
          }
        },
        "848ef537c6bc40cebda2bbd36f6d9982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b71257e5c1476b8c595d8b5bb36992",
            "placeholder": "​",
            "style": "IPY_MODEL_064efec8271648b99d2123452dc2808d",
            "value": " 7.65k/? [00:00&lt;00:00, 113kB/s]"
          }
        },
        "35075f7cf373419493f10aec0f4619d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca441b8da144e879308985081b900c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ca3d4226ee4b5185cd0b28c8481f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5258a69b94a8430f949231abc0cc293a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a68b69ca319427badbf1df3e34f941c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74b71257e5c1476b8c595d8b5bb36992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064efec8271648b99d2123452dc2808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52fdfa1320724070b1890f2b453cc13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f14ba59d9d184b35a85518459559ec03",
              "IPY_MODEL_c43b653474124487bf1b8323c3dde51e",
              "IPY_MODEL_c3bb8ae4febe4b0e804c25a95bd80725"
            ],
            "layout": "IPY_MODEL_6efc74d6a2ff4535ac7257605434d4d6"
          }
        },
        "f14ba59d9d184b35a85518459559ec03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a95add19560042e3b7e5040eb4cd31e4",
            "placeholder": "​",
            "style": "IPY_MODEL_c37883bb64b64676a7763e91422afcf1",
            "value": "100%"
          }
        },
        "c43b653474124487bf1b8323c3dde51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fada63477854bc3b90e44672997c9a9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87f919a0f9324fe19ae245aaf5b6eaea",
            "value": 1
          }
        },
        "c3bb8ae4febe4b0e804c25a95bd80725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a151b436144583b1d6cc3dbce905d6",
            "placeholder": "​",
            "style": "IPY_MODEL_d707d88e9b0041f3827ca33910f6bc88",
            "value": " 1/1 [00:00&lt;00:00,  3.86ba/s]"
          }
        },
        "6efc74d6a2ff4535ac7257605434d4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95add19560042e3b7e5040eb4cd31e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37883bb64b64676a7763e91422afcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fada63477854bc3b90e44672997c9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f919a0f9324fe19ae245aaf5b6eaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a151b436144583b1d6cc3dbce905d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d707d88e9b0041f3827ca33910f6bc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb9883f97b724adfbf5d5c038f1ff3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6d5d580e741432b9fb460df4f5af633",
              "IPY_MODEL_0249c2a5636a44adbcf35ad19b4137d4",
              "IPY_MODEL_a45586ece6fd4f0eae11557df5c0e7f5"
            ],
            "layout": "IPY_MODEL_30456c7bb974458080325ef6b0743013"
          }
        },
        "e6d5d580e741432b9fb460df4f5af633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cf528b6bb7c4e01bd0aef5edbabe3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_4fca95326bf54945814fa1cc3f37151f",
            "value": "100%"
          }
        },
        "0249c2a5636a44adbcf35ad19b4137d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9778f1b1917d41c0a715332de55e96df",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56b6cfb15e2142bdac1c314418577ae5",
            "value": 1
          }
        },
        "a45586ece6fd4f0eae11557df5c0e7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d478fe5cfd784f0a906107c421c8595f",
            "placeholder": "​",
            "style": "IPY_MODEL_f02609887767424d9c6be4f388ce46eb",
            "value": " 1/1 [00:00&lt;00:00, 10.38ba/s]"
          }
        },
        "30456c7bb974458080325ef6b0743013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf528b6bb7c4e01bd0aef5edbabe3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fca95326bf54945814fa1cc3f37151f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9778f1b1917d41c0a715332de55e96df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b6cfb15e2142bdac1c314418577ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d478fe5cfd784f0a906107c421c8595f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02609887767424d9c6be4f388ce46eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273d9e23b34d4192b7cc37b7a51d35ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_749f829f00a84ff48a6868cda102a551",
              "IPY_MODEL_47d7bfe782644fc2bd576521e5d977cc",
              "IPY_MODEL_47752cebdf9f45ec9176295fbec58f54"
            ],
            "layout": "IPY_MODEL_d4f6711798994912b7c96f10d2dc8c53"
          }
        },
        "749f829f00a84ff48a6868cda102a551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc381a554134311bc6028da692a75ab",
            "placeholder": "​",
            "style": "IPY_MODEL_e98da68527fb41b5ad741b58fc013bbb",
            "value": "100%"
          }
        },
        "47d7bfe782644fc2bd576521e5d977cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdb302b25884d3d9d1eb4619edace4e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_450418a80c4b41859a6bf17a88548aae",
            "value": 1
          }
        },
        "47752cebdf9f45ec9176295fbec58f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47294a53cdc4ddca379ccc5b05db951",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbd4626090743539f7762590dd6baac",
            "value": " 1/1 [00:00&lt;00:00, 10.41ba/s]"
          }
        },
        "d4f6711798994912b7c96f10d2dc8c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc381a554134311bc6028da692a75ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98da68527fb41b5ad741b58fc013bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fdb302b25884d3d9d1eb4619edace4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "450418a80c4b41859a6bf17a88548aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f47294a53cdc4ddca379ccc5b05db951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbd4626090743539f7762590dd6baac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will see how to **fine-tune** one of the **hugging-face Transformers mode**l for translating **Urdu** to **English** language."
      ],
      "metadata": {
        "id": "go7OXWrQLlND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages"
      ],
      "metadata": {
        "id": "sI9uXAlCK3tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "Fsa5ZKoCK5iI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "Og0jduzALM2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import datasets\n",
        "from datasets import Dataset, load_metric\n",
        "from google.colab import drive\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHWn8Q6zLKAL",
        "outputId": "58b254a1-9574-4a62-9d72-52b03b761c5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model Checkpoint"
      ],
      "metadata": {
        "id": "h-HS9LihL6dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-ur-en\""
      ],
      "metadata": {
        "id": "JDXhux0XLQxV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Drive"
      ],
      "metadata": {
        "id": "LC1BqNC4M-PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/fine_tuning_ur_en_machine_translation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b33rXsGvNA-g",
        "outputId": "c1f00868-d908-424a-bb09-8fd81f7e46b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/Colab Notebooks/fine_tuning_ur_en_machine_translation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Current Working Directory"
      ],
      "metadata": {
        "id": "KFiK7xzBKFgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "my_dir = os.getcwd() + '/'\n",
        "print(my_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjKDDyGKEPH",
        "outputId": "bab49d20-36aa-4dc9-df2d-92276cc2bb7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/fine_tuning_ur_en_machine_translation/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "KUh7Ia6oMLaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to translation file\n",
        "path_to_data = './urd.txt'\n",
        "\n",
        "# Read file\n",
        "translation_file = open(path_to_data,\"r\", encoding='utf-8') \n",
        "raw_data = translation_file.read()\n",
        "translation_file.close()\n",
        "\n",
        "# Parse data\n",
        "raw_data = raw_data.split('\\n')\n",
        "ur_en_pairs = [sentence.split('\\t') for sentence in  raw_data]\n",
        "del(ur_en_pairs[1143])"
      ],
      "metadata": {
        "id": "3hwJVuiIM48O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Custom DataSet"
      ],
      "metadata": {
        "id": "6TQ3Kmiekj8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = ur_en_pairs[:1000]\n",
        "validation_dataset = ur_en_pairs[1000:1100]\n",
        "testing_dataset = ur_en_pairs[1100:]"
      ],
      "metadata": {
        "id": "85PDdNNVto_d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict = [{'ur': i[1], 'en': i[0]} for i in training_dataset]\n",
        "test_dict = [{'ur': i[1], 'en': i[0]} for i in testing_dataset]\n",
        "validate_dict = [{'ur': i[1], 'en': i[0]} for i in validation_dataset]"
      ],
      "metadata": {
        "id": "lAL9LqoRXpzB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict = {'translation': train_dict}\n",
        "test_dict = {'translation': test_dict}\n",
        "validate_dict = {'translation': validate_dict}"
      ],
      "metadata": {
        "id": "RYC6qPSUcfhT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_dict(train_dict)\n",
        "test_dataset = Dataset.from_dict(test_dict)\n",
        "validate_dataset = Dataset.from_dict(validate_dict)\n"
      ],
      "metadata": {
        "id": "qE2B41dCgPZG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = datasets.DatasetDict({\"train\":train_dataset, \"validation\":validate_dataset, \"test\":test_dataset})"
      ],
      "metadata": {
        "id": "B2sng-tuj876"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqrjTyJ1kCyl",
        "outputId": "a72812f0-3a40-4edd-f06d-5c8a261b8648"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 43\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset['train'][855:865]"
      ],
      "metadata": {
        "id": "JtUFSO3MLy27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88bd5a7d-4174-408e-f8ea-dd3c6bff76de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': [{'en': \"You don't need to go in such a hurry.\",\n",
              "   'ur': 'تمھیں اتنی جلدی جانے کی ضرورت نہیں ہے۔'},\n",
              "  {'en': 'Your mother will be back before long.',\n",
              "   'ur': 'تمہاری امی بس آتی ہونگی۔'},\n",
              "  {'en': 'Your mother will be back before long.',\n",
              "   'ur': 'تمہاری ماں بس راستے میں ہو گی۔'},\n",
              "  {'en': 'All of us were busy cleaning the room.',\n",
              "   'ur': 'ہم سارے کمرے کی صفائی کرنے میں مصروف تھے۔'},\n",
              "  {'en': 'All you have to do is sweep the floor.',\n",
              "   'ur': 'تمہیں صرف زمین کی صفائی کرنی ہے۔'},\n",
              "  {'en': 'Different people have different ideas.',\n",
              "   'ur': 'مختلف لوگوں کے مختلف خیالات ہیں۔'},\n",
              "  {'en': 'English is studied all over the world.',\n",
              "   'ur': 'انگریزی پوری دنیا میں پڑھای جاتی ہے۔'},\n",
              "  {'en': 'Everyone was listening very carefully.',\n",
              "   'ur': 'سارے بڑے غور سے سن رہے تھے۔'},\n",
              "  {'en': 'He does not take care of his children.',\n",
              "   'ur': 'وہ اپنے بچوں کا خیال نہیں کرتا۔'},\n",
              "  {'en': 'I have a lot of passwords to remember.',\n",
              "   'ur': 'مجھے کافی زیادہ پاسورڈس یاد دکھنے پڑتے ہے۔'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a sense of how the data looks like, the following function will show some examples picked randomly in the dataset."
      ],
      "metadata": {
        "id": "06qO-s-zrH2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    \n",
        "    picks = []\n",
        "\n",
        "    for _ in range(num_examples):\n",
        "      \n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "    \n",
        "show_random_elements(final_dataset[\"train\"])"
      ],
      "metadata": {
        "id": "eINunKmdLz_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "65330f4c-83aa-4f8f-de82-479279b5b2fc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'en': 'Happy New Year!', 'ur': 'نیا سال مبارک۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'en': 'Do you want a ticket?', 'ur': 'تمھیں ٹکٹ چاہیے؟'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'en': 'I don't think Tom will be back.', 'ur': 'میرا نہیں خیال ٹام واپس آئے گا۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'en': 'Both my grandfather and grandmother are dead.', 'ur': 'میرے دادا اور دادی دونوں فوت ہو چکے ہیں۔'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'en': 'Tom's well.', 'ur': 'ٹام ٹھیک ہے۔'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use **metric** to evaluation (to compare our model to the benchmark). This can be easily done with the functions **load_metric**."
      ],
      "metadata": {
        "id": "p8TxB0thuR3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "tppHVEymL0VC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "d9b1093ef22d456896ebb259c87047ba",
            "b6477f5b91f5472b88abc77d3c583a75",
            "2cc388de1e6d471cb36fc79978ea03c6",
            "848ef537c6bc40cebda2bbd36f6d9982",
            "35075f7cf373419493f10aec0f4619d2",
            "cca441b8da144e879308985081b900c8",
            "a9ca3d4226ee4b5185cd0b28c8481f17",
            "5258a69b94a8430f949231abc0cc293a",
            "4a68b69ca319427badbf1df3e34f941c",
            "74b71257e5c1476b8c595d8b5bb36992",
            "064efec8271648b99d2123452dc2808d"
          ]
        },
        "outputId": "5f7e6c03-00b0-45fc-b6b5-29d522f3c0e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9b1093ef22d456896ebb259c87047ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "metadata": {
        "id": "x8yWaOuFL0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec38d5b-3b63-4056-ddff-0f528a4366af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
              "Produces BLEU scores along with its sufficient statistics\n",
              "from a source against one or more references.\n",
              "\n",
              "Args:\n",
              "    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n",
              "    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n",
              "    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n",
              "        - `'none'`: no smoothing\n",
              "        - `'floor'`: increment zero counts\n",
              "        - `'add-k'`: increment num/denom by k for n>1\n",
              "        - `'exp'`: exponential decay\n",
              "    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n",
              "    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n",
              "        - `'none'`: No tokenization.\n",
              "        - `'zh'`: Chinese tokenization.\n",
              "        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n",
              "        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n",
              "        - `'char'`: Language-agnostic character-level tokenization.\n",
              "        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n",
              "    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n",
              "    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n",
              "    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n",
              "\n",
              "Returns:\n",
              "    'score': BLEU score,\n",
              "    'counts': Counts,\n",
              "    'totals': Totals,\n",
              "    'precisions': Precisions,\n",
              "    'bp': Brevity penalty,\n",
              "    'sys_len': predictions length,\n",
              "    'ref_len': reference length,\n",
              "\n",
              "Examples:\n",
              "\n",
              "    Example 1:\n",
              "        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
              "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
              "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
              "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
              "        >>> print(list(results.keys()))\n",
              "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
              "        >>> print(round(results[\"score\"], 1))\n",
              "        100.0\n",
              "\n",
              "    Example 2:\n",
              "        >>> predictions = [\"hello there general kenobi\",\n",
              "        ...                 \"on our way to ankh morpork\"]\n",
              "        >>> references = [[\"hello there general kenobi\", \"hello there !\"],\n",
              "        ...                 [\"goodbye ankh morpork\", \"ankh morpork\"]]\n",
              "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
              "        >>> results = sacrebleu.compute(predictions=predictions,\n",
              "        ...                             references=references)\n",
              "        >>> print(list(results.keys()))\n",
              "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
              "        >>> print(round(results[\"score\"], 1))\n",
              "        39.8\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can call its **compute method** with your **predictions** and **labels**, which need to be **list of decoded strings** (list of list for the labels):"
      ],
      "metadata": {
        "id": "3MNkQ5jPu1jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_preds = [\"سنو ذرا\", \"hello there\"]\n",
        "fake_labels = [[\"سنو ذرا\"], [\"hello there\"]]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels,)"
      ],
      "metadata": {
        "id": "NMXrJInuL0lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd0f1f7-999a-4ea6-cf99-8a1467922c1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.0,\n",
              " 'counts': [4, 2, 0, 0],\n",
              " 'totals': [4, 2, 0, 0],\n",
              " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
              " 'bp': 1.0,\n",
              " 'sys_len': 4,\n",
              " 'ref_len': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing (Tokenization) the dataset"
      ],
      "metadata": {
        "id": "thHiCmGMvLKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a **Transformers Tokenizer** which will (as the name indicates) **tokenize the inputs** (including **converting the tokens to their corresponding IDs** in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we **instantiate our tokenizer with the AutoTokenizer.from_pretrained method**, which will ensure:\n",
        "\n",
        "we get a **tokenizer** that **corresponds** to the **model architecture** we want to use, we download the vocabulary used when pretraining this specific checkpoint. That vocabulary will be cached, so it's not downloaded again the next time we run the cell.\n",
        "\n",
        "If you downloaded the model manually, you can provide model present directory instead of model_checkpoint."
      ],
      "metadata": {
        "id": "gbfzwB8GvxB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "GVrqkxtcL0xd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(my_dir+\"save_tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VXepCt_JEmn",
        "outputId": "31bce043-faec-426e-9d87-b49a9b78ce31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/vocab.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/source.spm',\n",
              " '/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/target.spm',\n",
              " '/content/drive/MyDrive/Colab Notebooks/fine_tuning_ur_en_machine_translation/save_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('./save_tokenizer/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ3yfmmWEmvG",
        "outputId": "92b3c212-d592-447d-8e04-0ded36a6b722"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can directly call this tokenizer on one sentence or a pair of sentences:"
      ],
      "metadata": {
        "id": "0lE4aAVIK1s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
      ],
      "metadata": {
        "id": "2uArHXrsL00_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace7a077-1493-414a-a293-eb1e808ab466"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[56936, 9004, 2, 19741, 2889, 73, 4695, 73, 66, 7061, 15423, 67, 0], [4117, 15061, 66, 22, 73, 55163, 3565, 73, 66, 7061, 15423, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare the **targets for our model**, we need to tokenize them inside the **as_target_tokenizer** context manager. This will make sure the **tokenizer uses the special tokens** corresponding to the targets:"
      ],
      "metadata": {
        "id": "a7Ycf-zKLf1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
      ],
      "metadata": {
        "id": "ldpu2d2NL04v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4183e12-cf04-4186-d627-85212d63d464"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[20475, 2, 140, 155, 7166, 67, 0], [416, 22, 474, 7166, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3543: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Or\")\n",
        "\n",
        "tgt_text = [\"Hello, this one sentence!\", \"This is another sentence.\"],\n",
        "print(tokenizer(text_target = tgt_text))"
      ],
      "metadata": {
        "id": "0FzHDh5PL08K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33aad92b-4854-442c-8a96-ed156114af80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Or\n",
            "{'input_ids': [[20475, 2, 140, 155, 7166, 67, 416, 22, 474, 7166, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then write the **function** that will **preprocess our samples**. We just feed them to the **tokenizer** with the **argument truncation=True**. This will ensure that an input **longer** that what the model selected can handle will be **truncated to the maximum length accepted by the model**. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
      ],
      "metadata": {
        "id": "8NYdCYfgNRUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\n",
        "\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "\n",
        "source_lang = \"ur\"\n",
        "target_lang = \"en\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Getting Input and target\n",
        "    \"\"\"\n",
        "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "    \n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    \n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "OZb1OI2BL0_R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(final_dataset['train'][:2])"
      ],
      "metadata": {
        "id": "D3pz5QinL1B6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdf992b-9f24-4666-8a91-6c268a295d9f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[31585, 0], [349, 412, 0]], 'attention_mask': [[1, 1], [1, 1, 1]], 'labels': [[16918, 5, 0], [5569, 67, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **apply** this function on **all** the pairs of sentences in our dataset, we just use the **map** method of our **dataset** object we created earlier. This will **apply the function on all** the elements of all the splits in dataset, so our **training, validation and testing data** will be **preprocessed** in one single command"
      ],
      "metadata": {
        "id": "eEHe-hchN_aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = final_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "52fdfa1320724070b1890f2b453cc13e",
            "f14ba59d9d184b35a85518459559ec03",
            "c43b653474124487bf1b8323c3dde51e",
            "c3bb8ae4febe4b0e804c25a95bd80725",
            "6efc74d6a2ff4535ac7257605434d4d6",
            "a95add19560042e3b7e5040eb4cd31e4",
            "c37883bb64b64676a7763e91422afcf1",
            "6fada63477854bc3b90e44672997c9a9",
            "87f919a0f9324fe19ae245aaf5b6eaea",
            "a7a151b436144583b1d6cc3dbce905d6",
            "d707d88e9b0041f3827ca33910f6bc88",
            "cb9883f97b724adfbf5d5c038f1ff3b7",
            "e6d5d580e741432b9fb460df4f5af633",
            "0249c2a5636a44adbcf35ad19b4137d4",
            "a45586ece6fd4f0eae11557df5c0e7f5",
            "30456c7bb974458080325ef6b0743013",
            "3cf528b6bb7c4e01bd0aef5edbabe3fc",
            "4fca95326bf54945814fa1cc3f37151f",
            "9778f1b1917d41c0a715332de55e96df",
            "56b6cfb15e2142bdac1c314418577ae5",
            "d478fe5cfd784f0a906107c421c8595f",
            "f02609887767424d9c6be4f388ce46eb",
            "273d9e23b34d4192b7cc37b7a51d35ae",
            "749f829f00a84ff48a6868cda102a551",
            "47d7bfe782644fc2bd576521e5d977cc",
            "47752cebdf9f45ec9176295fbec58f54",
            "d4f6711798994912b7c96f10d2dc8c53",
            "dfc381a554134311bc6028da692a75ab",
            "e98da68527fb41b5ad741b58fc013bbb",
            "5fdb302b25884d3d9d1eb4619edace4e",
            "450418a80c4b41859a6bf17a88548aae",
            "f47294a53cdc4ddca379ccc5b05db951",
            "bfbd4626090743539f7762590dd6baac"
          ]
        },
        "id": "f7nA7y0NOPkR",
        "outputId": "a9f08099-29af-4cdb-d023-ef94e1b03719"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52fdfa1320724070b1890f2b453cc13e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb9883f97b724adfbf5d5c038f1ff3b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "273d9e23b34d4192b7cc37b7a51d35ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model\n",
        "Now that our data is ready, we can **download the pretrained** model and fine-tune it. Since our task is of the **sequence-to-sequence** kind, we use the **AutoModelForSeq2SeqLM** class. Like with the tokenizer, the from_pretrained method will download and cache the model for us."
      ],
      "metadata": {
        "id": "fXbeUUloN_zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "wcDrAGKbWfBQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model"
      ],
      "metadata": {
        "id": "lK5UMQkZXXaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(my_dir+\"save_model\")"
      ],
      "metadata": {
        "id": "5ttW5jmPXWW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model from Save Directory"
      ],
      "metadata": {
        "id": "mTvi_zRNcRJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained('save_model')"
      ],
      "metadata": {
        "id": "G0ZiwV4CcK8a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **instantiate** a **Seq2SeqTrainer**, we will need to define **three** more things. The most important is the **Seq2SeqTrainingArguments**, which is a class that contains all the **attributes to customize the training**. It requires one **folder name**, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ],
      "metadata": {
        "id": "hOn6e4xTZtI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "print(\"Model name:\",model_name)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=20,\n",
        "    predict_with_generate=True   \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHi74wP5Z_CR",
        "outputId": "d2804406-3d6f-490a-cd06-afdae6dae859"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name: opus-mt-ur-en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twlIOxf3Z_a4",
        "outputId": "dda02035-e131-4b65-a7ec-ef521c3e9a58"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTrainingArguments(output_dir='opus-mt-ur-en-finetuned-ur-to-en', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=2e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=20, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='opus-mt-ur-en-finetuned-ur-to-en/runs/Sep29_09-26-57_5150f46f7e4c', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=3, save_on_each_node=False, no_cuda=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, past_index=-1, run_name='opus-mt-ur-en-finetuned-ur-to-en', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_HF: 'adamw_hf'>, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=False, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, sortish_sampler=False, predict_with_generate=True, generation_max_length=None, generation_num_beams=None)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we **set** the **evaluation** to be done at the **end of each epoch**, tweak the learning rate, use the **batch_size** defined at the top of the cell and customize the weight decay. Since the **Seq2SeqTrainer** will **save** the **model** regularly and our dataset is quite large, we tell it to make** three saves maximum**. Lastly, we use the **predict_with_generate** option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
        "\n",
        "Model will **save** under **{model_name}-finetuned-{source_lang}-to-{target_lang}** directory\n",
        "\n",
        "Then, we need a special kind of **data collator**, which will not only **pad** the **inputs** to the **maximum length** in the batch, but also the **labels**:"
      ],
      "metadata": {
        "id": "PbpBCh4Sa4Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "_6XyXYKKcN0T"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing to define for our **Seq2SeqTrainer** is **how to compute the metrics** from the **predictions**. We need to define a function for this, which will just use the **metric** we loaded earlier, and we have to do a bit of **pre-processing to decode the predictions into texts**"
      ],
      "metadata": {
        "id": "w42ASTbucdK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions = decoded_preds, references = decoded_labels)\n",
        "\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    \n",
        "    return result"
      ],
      "metadata": {
        "id": "VHQNv35sXqf_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we just need to pass all of this along with our datasets to the Seq2SeqTrainer:"
      ],
      "metadata": {
        "id": "5T0ncMZIOAIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset = tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"],\n",
        "    data_collator = data_collator,\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics = compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "kk_CGC2edbhy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now finetune our model by just calling the train method:"
      ],
      "metadata": {
        "id": "RdSFg0itOAMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6lZ439WNzvY",
        "outputId": "0c0dcd32-7683-47e6-f10a-8bc78feab7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 1000\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1260\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1257' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1257/1260 1:18:49 < 00:11, 0.27 it/s, Epoch 19.94/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.906647</td>\n",
              "      <td>20.323500</td>\n",
              "      <td>11.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.927477</td>\n",
              "      <td>20.884200</td>\n",
              "      <td>11.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.978731</td>\n",
              "      <td>21.896200</td>\n",
              "      <td>11.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.008490</td>\n",
              "      <td>20.661300</td>\n",
              "      <td>11.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.054694</td>\n",
              "      <td>21.032600</td>\n",
              "      <td>11.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.093682</td>\n",
              "      <td>20.456300</td>\n",
              "      <td>11.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.131332</td>\n",
              "      <td>19.950400</td>\n",
              "      <td>11.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.154000</td>\n",
              "      <td>19.529000</td>\n",
              "      <td>11.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.163179</td>\n",
              "      <td>20.917400</td>\n",
              "      <td>11.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.218451</td>\n",
              "      <td>21.342500</td>\n",
              "      <td>11.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.243308</td>\n",
              "      <td>20.197800</td>\n",
              "      <td>11.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.267649</td>\n",
              "      <td>19.602600</td>\n",
              "      <td>11.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.278270</td>\n",
              "      <td>19.729000</td>\n",
              "      <td>11.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.288073</td>\n",
              "      <td>18.963300</td>\n",
              "      <td>11.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.562300</td>\n",
              "      <td>2.306378</td>\n",
              "      <td>20.078200</td>\n",
              "      <td>11.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>2.319335</td>\n",
              "      <td>19.611700</td>\n",
              "      <td>11.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>2.329680</td>\n",
              "      <td>19.783200</td>\n",
              "      <td>11.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>2.335247</td>\n",
              "      <td>19.732100</td>\n",
              "      <td>11.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>2.337125</td>\n",
              "      <td>19.672800</td>\n",
              "      <td>11.190000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500\n",
            "Configuration saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/config.json\n",
            "Model weights saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000\n",
            "Configuration saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/config.json\n",
            "Model weights saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5FV6N1JjeG1",
        "outputId": "a31375d7-0b55-4b88-9217-f874fc559e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to opus-mt-ur-en-finetuned-ur-to-en\n",
            "Configuration saved in opus-mt-ur-en-finetuned-ur-to-en/config.json\n",
            "Model weights saved in opus-mt-ur-en-finetuned-ur-to-en/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-ur-en-finetuned-ur-to-en/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-ur-en-finetuned-ur-to-en/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('opus-mt-ur-en-finetuned-ur-to-en'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSPbTW_Sdqnv",
        "outputId": "15624434-d3ca-4d53-da19-8756a860a206"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opus-mt-ur-en-finetuned-ur-to-en/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/pytorch_model.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/runs/Sep28_18-52-27_8ea1380cdee9/events.out.tfevents.1664391490.8ea1380cdee9.52.0\n",
            "opus-mt-ur-en-finetuned-ur-to-en/runs/Sep28_18-52-27_8ea1380cdee9/1664391490.623785/events.out.tfevents.1664391490.8ea1380cdee9.52.1\n",
            "opus-mt-ur-en-finetuned-ur-to-en/runs/Sep28_19-28-22_8ea1380cdee9/events.out.tfevents.1664393312.8ea1380cdee9.52.2\n",
            "opus-mt-ur-en-finetuned-ur-to-en/runs/Sep28_19-28-22_8ea1380cdee9/1664393312.3949056/events.out.tfevents.1664393312.8ea1380cdee9.52.3\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/pytorch_model.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/optimizer.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/scheduler.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/trainer_state.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-500/rng_state.pth\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/pytorch_model.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/tokenizer_config.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/special_tokens_map.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/vocab.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/source.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/target.spm\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/training_args.bin\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/optimizer.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/scheduler.pt\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/trainer_state.json\n",
            "opus-mt-ur-en-finetuned-ur-to-en/checkpoint-1000/rng_state.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our fine tuned model already saved under opus-mt-ur-en-finetuned-ur-to-en/\n",
        "\n",
        "Load the model and translate some text from english to romanian"
      ],
      "metadata": {
        "id": "nXBgZytef2rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Sentence to translate\n",
        "src_text = ['میں رات کے کھانے سے پہلے سونا چاہتا ہوں']\n",
        "\n",
        "model_name = 'opus-mt-ur-en-finetuned-ur-to-en'\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This tokenizer inherits from PreTrainedTokenizer which contains most of the\n",
        "main methods. Users should refer to this superclass for more information\n",
        "regarding those methods.\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(tokenizer.supported_language_codes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhzYp4XDgAhy",
        "outputId": "de5229d9-4c09-4f76-e498-c79b7f8ce894"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file source.spm\n",
            "loading file target.spm\n",
            "loading file vocab.json\n",
            "loading file target_vocab.json\n",
            "loading file tokenizer_config.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bare Marian Model outputting raw hidden-states without any specific head on top. This model inherits from PreTrainedModel. Check the superclass documentation for the generic methods the library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads etc.)"
      ],
      "metadata": {
        "id": "gh131bJnnWCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
        "\n",
        "result = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArV-OKbwgbZX",
        "outputId": "3b7afd83-9591-438c-dae1-d1af391f923c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file opus-mt-ur-en-finetuned-ur-to-en/config.json\n",
            "Model config MarianConfig {\n",
            "  \"_name_or_path\": \"opus-mt-ur-en-finetuned-ur-to-en\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      62024\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 62024,\n",
            "  \"decoder_vocab_size\": 62025,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"extra_pos_embeddings\": 62025,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 62024,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 62025\n",
            "}\n",
            "\n",
            "loading weights file opus-mt-ur-en-finetuned-ur-to-en/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing MarianMTModel.\n",
            "\n",
            "All the weights of MarianMTModel were initialized from the model checkpoint at opus-mt-ur-en-finetuned-ur-to-en.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrh9UAs9n-Bj",
        "outputId": "75b4f7f3-ea0f-478c-c725-77824f36b705"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I want to sleep before dinner.']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "our fine tune model is doing far better than pre-trained model and close to google translator"
      ],
      "metadata": {
        "id": "ne-XERwxf3sL"
      }
    }
  ]
}